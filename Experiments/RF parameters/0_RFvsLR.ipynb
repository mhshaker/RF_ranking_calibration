{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "sys.path.append('../../') # to access the files in higher directories\n",
    "sys.path.append('../') # to access the files in higher directories\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import Data.data_provider as dp\n",
    "import core as cal\n",
    "from estimators.IR_RF_estimator import IR_RF\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "calib_methods = [\"RF\"] #cal.calib_methods.copy() \n",
    "metrics = [\"acc\", \"tce\"]#cal.metrics.copy()\n",
    "\n",
    "plot = True\n",
    " \n",
    "params = {\n",
    "    \"runs\": 3,\n",
    "    \"n_tree\": [10],#[2, 5, 10, 20], \n",
    "    \"data_size\": 10000,\n",
    "    \"n_features\": 2,\n",
    "    \"oob\": False,\n",
    "    \"test_split\": 0.3,\n",
    "    \"calib_split\": 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "\n",
    "X, y, tp = dp.make_classification_gaussian_with_true_prob(params[\"data_size\"], params[\"n_features\"], \n",
    "                                                          class1_mean_min=0, \n",
    "                                                          class1_mean_max=1,\n",
    "\n",
    "                                                          class2_mean_min=1, \n",
    "                                                          class2_mean_max=3, \n",
    "\n",
    "                                                          seed=0)\n",
    "\n",
    "# plot data\n",
    "# plt.scatter(X[:,0], X[:,1], c=y)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "calib_results_dict = {}\n",
    "data_dict = {} # results for each data set will be saved in here.\n",
    "for exp_trees in params[\"n_tree\"]:\n",
    "\n",
    "    # Data\n",
    "    exp_data_name = str(exp_trees)\n",
    "    data_list.append(exp_data_name)\n",
    "\n",
    "    for seed in range(params[\"runs\"]): # running the same dataset multiple times\n",
    "        # split the data\n",
    "        data = cal.split_train_calib_test(exp_data_name, X, y, params[\"test_split\"], params[\"calib_split\"], seed, tp)\n",
    "\n",
    "        # train models\n",
    "        models = {}\n",
    "\n",
    "        irrf = IR_RF(n_estimators=exp_trees, oob_score=params[\"oob\"], random_state=seed).fit(data[\"x_train\"], data[\"y_train\"])\n",
    "        models[\"RF\"] = irrf\n",
    "\n",
    "        lr = LogisticRegression(random_state=0).fit(data[\"x_train\"], data[\"y_train\"])\n",
    "        models[\"LR\"] = lr\n",
    "\n",
    "        svm = SVC(probability=True, random_state=0).fit(data[\"x_train\"], data[\"y_train\"])\n",
    "        models[\"SVM\"] = svm\n",
    "\n",
    "        # calibration\n",
    "        res = cal.model_calibration(models, data, metrics) # res is a dict with all the metrics results as well as RF probs and every calibration method decision for every test data point\n",
    "        \n",
    "        # lr = LogisticRegression(random_state=0).fit(data[\"x_train\"], data[\"y_train\"])\n",
    "        # lr_p_test = lr.predict_proba(data[\"x_test\"])\n",
    "        # res[data[\"name\"] + \"_LR_prob\"] = lr_p_test\n",
    "        # res[data[\"name\"] + \"_LR_decision\"] = np.argmax(lr_p_test, axis=1)\n",
    "        # res[data[\"name\"] + \"_LR_acc\"] = accuracy_score(data[\"y_test\"], res[data[\"name\"] + \"_LR_decision\"])\n",
    "        # res[data[\"name\"] + \"_LR_tce\"] = mean_squared_error(data[\"tp_test\"], res[data[\"name\"] + \"_LR_prob\"][:,1])\n",
    "\n",
    "        # svm = SVC(probability=True, random_state=0).fit(data[\"x_train\"], data[\"y_train\"])\n",
    "        # svm_p_test = svm.predict_proba(data[\"x_test\"])\n",
    "        # res[data[\"name\"] + \"_SVM_prob\"] = svm_p_test\n",
    "        # res[data[\"name\"] + \"_SVM_decision\"] = np.argmax(svm_p_test, axis=1)\n",
    "        # res[data[\"name\"] + \"_SVM_acc\"] = accuracy_score(data[\"y_test\"], res[data[\"name\"] + \"_SVM_decision\"])\n",
    "        # res[data[\"name\"] + \"_SVM_tce\"] = mean_squared_error(data[\"tp_test\"], res[data[\"name\"] + \"_SVM_prob\"][:,1])\n",
    "\n",
    "\n",
    "        data_dict = cal.update_runs(data_dict, res) # calib results for every run for the same dataset is aggregated in data_dict (ex. acc of every run as an array)\n",
    "        \n",
    "        if plot:\n",
    "            # plot RF\n",
    "            cal.plot_probs(exp_data_name, res, data, calib_methods, seed, True) \n",
    "\n",
    "            # plot LR\n",
    "            plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "            colors = ['black', 'red']\n",
    "            plt.scatter(data[\"tp_test\"], lr_p_test[:,1], marker='.', c=[colors[c] for c in data[\"y_test\"].astype(int)])\n",
    "            plt.scatter(data[\"tp_test\"], res[f\"{exp_data_name}_RF_prob\"][:,1], marker='.', c=[colors[c] for c in data[\"y_test\"].astype(int)], alpha=0.1)\n",
    "            plt.xlabel(\"True probability\")\n",
    "            plt.ylabel(\"Predicted probability\")\n",
    "            red_patch = plt.plot([],[], marker='o', markersize=10, color='red', linestyle='')[0]\n",
    "            black_patch = plt.plot([],[], marker='o', markersize=10, color='black', linestyle='')[0]\n",
    "            calib_patch = plt.plot([],[], marker='_', markersize=15, color='blue', linestyle='')[0]\n",
    "            plt.legend((red_patch, black_patch, calib_patch), ('Class 0', 'Class 1', \"LR\"))\n",
    "            path = f\"../../results/Synthetic/plots/{seed}/LR\"\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "            plt.savefig(f\"{path}/LR_{exp_data_name}.png\")\n",
    "            plt.close()\n",
    "\n",
    "            # plot LR\n",
    "            plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "            colors = ['black', 'red']\n",
    "            plt.scatter(data[\"tp_test\"], svm_p_test[:,1], marker='.', c=[colors[c] for c in data[\"y_test\"].astype(int)])\n",
    "            plt.scatter(data[\"tp_test\"], res[f\"{exp_data_name}_RF_prob\"][:,1], marker='.', c=[colors[c] for c in data[\"y_test\"].astype(int)], alpha=0.1)\n",
    "            plt.xlabel(\"True probability\")\n",
    "            plt.ylabel(\"Predicted probability\")\n",
    "            red_patch = plt.plot([],[], marker='o', markersize=10, color='red', linestyle='')[0]\n",
    "            black_patch = plt.plot([],[], marker='o', markersize=10, color='black', linestyle='')[0]\n",
    "            calib_patch = plt.plot([],[], marker='_', markersize=15, color='blue', linestyle='')[0]\n",
    "            plt.legend((red_patch, black_patch, calib_patch), ('Class 0', 'Class 1', \"SVM\"))\n",
    "            path = f\"../../results/Synthetic/plots/{seed}/SVM\"\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "            plt.savefig(f\"{path}/SVM_{exp_data_name}.png\")\n",
    "            plt.close()\n",
    "\n",
    "        calib_results_dict.update(data_dict) # merge results of all datasets together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "calib_methods.append(\"LR\")   \n",
    "calib_methods.append(\"SVM\")   \n",
    "tables = cal.mean_and_ranking_table(calib_results_dict, metrics, calib_methods, data_list, mean_and_rank=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RF</th>\n",
       "      <th>LR</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.765667</td>\n",
       "      <td>2.378</td>\n",
       "      <td>2.370667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            RF     LR       SVM\n",
       "Data                           \n",
       "10    0.765667  2.378  2.370667"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[\"acc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RF</th>\n",
       "      <th>LR</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.019225</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.021664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            RF        LR       SVM\n",
       "Data                              \n",
       "10    0.019225  0.001122  0.021664"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[\"tce\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RFcalib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
