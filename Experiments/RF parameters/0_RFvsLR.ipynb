{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "sys.path.append('../../') # to access the files in higher directories\n",
    "sys.path.append('../') # to access the files in higher directories\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import Data.data_provider as dp\n",
    "import core as cal\n",
    "from estimators.IR_RF_estimator import IR_RF\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "calib_methods = [\"RF\"] #cal.calib_methods.copy() \n",
    "metrics = [\"acc\", \"tce\"]#cal.metrics.copy()\n",
    "\n",
    "plot = True\n",
    " \n",
    "params = {\n",
    "    \"runs\": 1,\n",
    "    \"n_tree\": [2, 5, 10, 20], \n",
    "    \"data_size\": 10000,\n",
    "    \"n_features\": 2,\n",
    "    \"oob\": False,\n",
    "    \"test_split\": 0.3,\n",
    "    \"calib_split\": 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "\n",
    "X, y, tp = dp.make_classification_gaussian_with_true_prob(params[\"data_size\"], params[\"n_features\"], \n",
    "                                                          class1_mean_min=0, \n",
    "                                                          class1_mean_max=1,\n",
    "\n",
    "                                                          class2_mean_min=1, \n",
    "                                                          class2_mean_max=3, \n",
    "\n",
    "                                                          seed=0)\n",
    "\n",
    "# plot data\n",
    "# plt.scatter(X[:,0], X[:,1], c=y)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'2_RF_acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[146], line 35\u001b[0m\n\u001b[1;32m     18\u001b[0m res \u001b[39m=\u001b[39m cal\u001b[39m.\u001b[39mcalibration(irrf, data, calib_methods, metrics) \u001b[39m# res is a dict with all the metrics results as well as RF probs and every calibration method decision for every test data point\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39m# lr = LogisticRegression(random_state=0).fit(data[\"x_train\"], data[\"y_train\"])\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39m# lr_p_test = lr.predict_proba(data[\"x_test\"])\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39m# res[data[\"name\"] + \"_LR_prob\"] = lr_p_test\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39m# res[data[\"name\"] + \"_SVM_acc\"] = accuracy_score(data[\"y_test\"], res[data[\"name\"] + \"_SVM_decision\"])\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39m# res[data[\"name\"] + \"_SVM_tce\"] = mean_squared_error(data[\"tp_test\"], res[data[\"name\"] + \"_SVM_prob\"][:,1])\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m data_dict \u001b[39m=\u001b[39m cal\u001b[39m.\u001b[39;49mupdate_runs(data_dict, res) \u001b[39m# calib results for every run for the same dataset is aggregated in data_dict (ex. acc of every run as an array)\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39mif\u001b[39;00m plot:\n\u001b[1;32m     38\u001b[0m     \u001b[39m# plot RF\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     cal\u001b[39m.\u001b[39mplot_probs(exp_data_name, res, data, calib_methods, seed, \u001b[39mTrue\u001b[39;00m) \n",
      "File \u001b[0;32m~/Documents/PhD/Projects/RF_ranking_calibration/Experiments/RF parameters/../core.py:243\u001b[0m, in \u001b[0;36mupdate_runs\u001b[0;34m(ref_dict, new_dict)\u001b[0m\n\u001b[1;32m    239\u001b[0m res_dict \u001b[39m=\u001b[39m ref_dict\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    240\u001b[0m \u001b[39m# print(\"new_dict keys\", len(new_dict.keys()))\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \u001b[39m# print(\"res_dict keys\", len(res_dict.keys()))\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[39m# print(\"---------------------------------\")\u001b[39;00m\n\u001b[0;32m--> 243\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m ref_dict\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    244\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m_prob\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m k \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m_decision\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m k:\n\u001b[1;32m    245\u001b[0m         \u001b[39mdel\u001b[39;00m res_dict[k]\n",
      "\u001b[0;31mKeyError\u001b[0m: '2_RF_acc'"
     ]
    }
   ],
   "source": [
    "calib_results_dict = {}\n",
    "data_dict = {} # results for each data set will be saved in here.\n",
    "for exp_trees in params[\"n_tree\"]:\n",
    "\n",
    "    # Data\n",
    "    exp_data_name = str(exp_trees)\n",
    "    data_list.append(exp_data_name)\n",
    "\n",
    "    for seed in range(params[\"runs\"]): # running the same dataset multiple times\n",
    "        # split the data\n",
    "        data = cal.split_train_calib_test(exp_data_name, X, y, params[\"test_split\"], params[\"calib_split\"], seed, tp)\n",
    "\n",
    "        # train model\n",
    "        irrf = IR_RF(n_estimators=exp_trees, oob_score=params[\"oob\"], random_state=seed)\n",
    "        irrf.fit(data[\"x_train\"], data[\"y_train\"])\n",
    "\n",
    "        # calibration\n",
    "        res = cal.calibration(irrf, data, calib_methods, metrics) # res is a dict with all the metrics results as well as RF probs and every calibration method decision for every test data point\n",
    "        \n",
    "        lr = LogisticRegression(random_state=0).fit(data[\"x_train\"], data[\"y_train\"])\n",
    "        lr_p_test = lr.predict_proba(data[\"x_test\"])\n",
    "        res[data[\"name\"] + \"_LR_prob\"] = lr_p_test\n",
    "        res[data[\"name\"] + \"_LR_decision\"] = np.argmax(lr_p_test, axis=1)\n",
    "        res[data[\"name\"] + \"_LR_acc\"] = accuracy_score(data[\"y_test\"], res[data[\"name\"] + \"_LR_decision\"])\n",
    "        res[data[\"name\"] + \"_LR_tce\"] = mean_squared_error(data[\"tp_test\"], res[data[\"name\"] + \"_LR_prob\"][:,1])\n",
    "\n",
    "        svm = SVC(probability=True, random_state=0).fit(data[\"x_train\"], data[\"y_train\"])\n",
    "        svm_p_test = svm.predict_proba(data[\"x_test\"])\n",
    "        res[data[\"name\"] + \"_SVM_prob\"] = svm_p_test\n",
    "        res[data[\"name\"] + \"_SVM_decision\"] = np.argmax(svm_p_test, axis=1)\n",
    "        res[data[\"name\"] + \"_SVM_acc\"] = accuracy_score(data[\"y_test\"], res[data[\"name\"] + \"_SVM_decision\"])\n",
    "        res[data[\"name\"] + \"_SVM_tce\"] = mean_squared_error(data[\"tp_test\"], res[data[\"name\"] + \"_SVM_prob\"][:,1])\n",
    "\n",
    "\n",
    "        data_dict = cal.update_runs(data_dict, res) # calib results for every run for the same dataset is aggregated in data_dict (ex. acc of every run as an array)\n",
    "        \n",
    "        if plot:\n",
    "            # plot RF\n",
    "            cal.plot_probs(exp_data_name, res, data, calib_methods, seed, True) \n",
    "\n",
    "            # plot LR\n",
    "            plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "            colors = ['black', 'red']\n",
    "            plt.scatter(data[\"tp_test\"], lr_p_test[:,1], marker='.', c=[colors[c] for c in data[\"y_test\"].astype(int)])\n",
    "            plt.scatter(data[\"tp_test\"], res[f\"{exp_data_name}_RF_prob\"][:,1], marker='.', c=[colors[c] for c in data[\"y_test\"].astype(int)], alpha=0.1)\n",
    "            plt.xlabel(\"True probability\")\n",
    "            plt.ylabel(\"Predicted probability\")\n",
    "            red_patch = plt.plot([],[], marker='o', markersize=10, color='red', linestyle='')[0]\n",
    "            black_patch = plt.plot([],[], marker='o', markersize=10, color='black', linestyle='')[0]\n",
    "            calib_patch = plt.plot([],[], marker='_', markersize=15, color='blue', linestyle='')[0]\n",
    "            plt.legend((red_patch, black_patch, calib_patch), ('Class 0', 'Class 1', \"LR\"))\n",
    "            path = f\"../../results/Synthetic/plots/{seed}/LR\"\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "            plt.savefig(f\"{path}/LR_{exp_data_name}.png\")\n",
    "            plt.close()\n",
    "\n",
    "            # plot LR\n",
    "            plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "            colors = ['black', 'red']\n",
    "            plt.scatter(data[\"tp_test\"], svm_p_test[:,1], marker='.', c=[colors[c] for c in data[\"y_test\"].astype(int)])\n",
    "            plt.scatter(data[\"tp_test\"], res[f\"{exp_data_name}_RF_prob\"][:,1], marker='.', c=[colors[c] for c in data[\"y_test\"].astype(int)], alpha=0.1)\n",
    "            plt.xlabel(\"True probability\")\n",
    "            plt.ylabel(\"Predicted probability\")\n",
    "            red_patch = plt.plot([],[], marker='o', markersize=10, color='red', linestyle='')[0]\n",
    "            black_patch = plt.plot([],[], marker='o', markersize=10, color='black', linestyle='')[0]\n",
    "            calib_patch = plt.plot([],[], marker='_', markersize=15, color='blue', linestyle='')[0]\n",
    "            plt.legend((red_patch, black_patch, calib_patch), ('Class 0', 'Class 1', \"SVM\"))\n",
    "            path = f\"../../results/Synthetic/plots/{seed}/SVM\"\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "            plt.savefig(f\"{path}/SVM_{exp_data_name}.png\")\n",
    "            plt.close()\n",
    "\n",
    "        calib_results_dict.update(data_dict) # merge results of all datasets together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calib_methods.append(\"LR\")   \n",
    "calib_methods.append(\"SVM\")   \n",
    "tables = cal.mean_and_ranking_table(calib_results_dict, metrics, calib_methods, data_list, mean_and_rank=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RF</th>\n",
       "      <th>LR</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>0.764</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RF     LR    SVM\n",
       "Data                     \n",
       "S     0.764  0.795  0.793"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[\"acc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RF</th>\n",
       "      <th>LR</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>0.019014</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.007113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            RF        LR       SVM\n",
       "Data                              \n",
       "S     0.019014  0.000391  0.007113"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[\"tce\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RFcalib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
