{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How changing the difficulty of a dataset effects the calibration methods\n",
    "# Change difficulty of generated data such that the RF atcheaves ACC in a range betwean 100% to 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "sys.path.append('../../') # to access the files in higher directories\n",
    "sys.path.append('../') # to access the files in higher directories\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import Data.data_provider as dp\n",
    "import core as cal\n",
    "from estimators.IR_RF_estimator import IR_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "calib_methods = cal.calib_methods.copy() #[\"RF\", \"Platt\" , \"ISO\", \"Rank\", \"CRF\", \"VA\", \"Beta\", \"Elkan\", \"tlr\", \"Line\"]\n",
    "metrics = cal.metrics.copy() #[\"acc\", \"auc\", \"brier\", \"logloss\", \"ece\", \"tce\"]\n",
    "\n",
    "data_name = \"S_difficulty\"\n",
    "\n",
    "params = {\n",
    "    \"runs\": 50,\n",
    "    \"data_difficulty\": [10, 20, 40, 60, 80, 100], # as percentage of the x_calib data\n",
    "    \"data_size\": 1000,\n",
    "    \"n_features\": 40,\n",
    "    \"n_estimators\": 100,\n",
    "    \"oob\": False,\n",
    "    \"test_split\": 0.3,\n",
    "    \"calib_split\": 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8466666666666667"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 0\n",
    "X, y, tp = dp.make_classification_gaussian_with_true_prob(params[\"data_size\"], params[\"n_features\"], seed)\n",
    "data = cal.split_train_calib_test(\"diff_test\", X, y, params[\"test_split\"], params[\"calib_split\"], seed)\n",
    "irrf = IR_RF(n_estimators=params[\"n_estimators\"], oob_score=params[\"oob\"], random_state=seed)\n",
    "irrf.fit(data[\"x_train\"], data[\"y_train\"])\n",
    "acc = irrf.score(data[\"x_test\"], data[\"y_test\"])\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tp_test'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m     irrf\u001b[39m.\u001b[39mfit(data[\u001b[39m\"\u001b[39m\u001b[39mx_train\u001b[39m\u001b[39m\"\u001b[39m], data[\u001b[39m\"\u001b[39m\u001b[39my_train\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     20\u001b[0m     \u001b[39m# calibration\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     res \u001b[39m=\u001b[39m cal\u001b[39m.\u001b[39;49mcalibration(irrf, data, calib_methods, metrics) \u001b[39m# res is a dict with all the metrics results as well as RF probs and every calibration method decision for every test data point\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     data_dict \u001b[39m=\u001b[39m cal\u001b[39m.\u001b[39mupdate_runs(data_dict, res) \u001b[39m# calib results for every run for the same dataset is aggregated in data_dict (ex. acc of every run as an array)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m calib_results_dict\u001b[39m.\u001b[39mupdate(data_dict) \u001b[39m# merge results of all datasets together\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/PhD/Projects/RF_ranking_calibration/Experiments/Data manipulation/../core.py:210\u001b[0m, in \u001b[0;36mcalibration\u001b[0;34m(RF, data, calib_methods, metrics, plot_bins, laplace)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtce\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m metrics:\n\u001b[1;32m    209\u001b[0m     \u001b[39mfor\u001b[39;00m method \u001b[39min\u001b[39;00m calib_methods:\n\u001b[0;32m--> 210\u001b[0m         results_dict[data[\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m method \u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_tce\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mappend(mean_squared_error(data[\u001b[39m\"\u001b[39;49m\u001b[39mtp_test\u001b[39;49m\u001b[39m\"\u001b[39;49m], results_dict[data[\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m method \u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_prob\u001b[39m\u001b[39m\"\u001b[39m][:,\u001b[39m1\u001b[39m]))\n\u001b[1;32m    212\u001b[0m \u001b[39mreturn\u001b[39;00m results_dict\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tp_test'"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "calib_results_dict = {}\n",
    "\n",
    "for exp_data_difficulty in params[\"data_difficulty\"]:\n",
    "\n",
    "    # Data\n",
    "    exp_data_name = str(exp_data_difficulty) # data_name + \"_\" + \n",
    "    data_list.append(exp_data_name)\n",
    "    X, y, tp = dp.make_classification_gaussian_with_true_prob(params[\"data_size\"], params[\"n_features\"], 0)\n",
    "\n",
    "    data_dict = {} # results for each data set will be saved in here.\n",
    "    for seed in range(params[\"runs\"]): # running the same dataset multiple times\n",
    "        # split the data\n",
    "        data = cal.split_train_calib_test(exp_data_name, X, y, params[\"test_split\"], params[\"calib_split\"], seed)\n",
    "\n",
    "        # train model\n",
    "        irrf = IR_RF(n_estimators=params[\"n_estimators\"], oob_score=params[\"oob\"], random_state=seed)\n",
    "        irrf.fit(data[\"x_train\"], data[\"y_train\"])\n",
    "\n",
    "        # calibration\n",
    "        res = cal.calibration(irrf, data, calib_methods, metrics) # res is a dict with all the metrics results as well as RF probs and every calibration method decision for every test data point\n",
    "        data_dict = cal.update_runs(data_dict, res) # calib results for every run for the same dataset is aggregated in data_dict (ex. acc of every run as an array)\n",
    "    calib_results_dict.update(data_dict) # merge results of all datasets together\n",
    "tables = cal.mean_and_ranking_table(calib_results_dict, metrics, calib_methods, data_list, mean_and_rank=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = cal.mean_and_ranking_table(calib_results_dict, metrics, calib_methods, data_list, mean_and_rank=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_calib_methods = calib_methods\n",
    "plot_calib_methods.remove(\"VA\")\n",
    "plot_calib_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in metrics:\n",
    "    ax = tables[metric][plot_calib_methods].plot()\n",
    "    ax.set_xlabel(\"Calib_size\")\n",
    "    ax.set_ylabel(metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
