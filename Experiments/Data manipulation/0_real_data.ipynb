{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How changing the dataset sample size effects the calibration methods\n",
    "# Fix training dataset size and change the calib set samples - best method is one that gets max calib with least data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "sys.path.append('../../') # to access the files in higher directories\n",
    "sys.path.append('../') # to access the files in higher directories\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import Data.data_provider as dp\n",
    "import core as cal\n",
    "from estimators.IR_RF_estimator import IR_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "calib_methods = [\"RF\", \"Platt\" , \"ISO\", \"Rank\", \"CRF\", \"VA\", \"Beta\", \"Elkan\", \"tlr\"]\n",
    "metrics = [\"acc\", \"auc\", \"brier\", \"ece\", \"logloss\"]\n",
    "data_list = [\"spambase\", \"climate\", \"QSAR\", \"bank\", \"climate\", \"parkinsons\", \"vertebral\", \"ionosphere\", \"diabetes\", \"breast\", \"blod\"]\n",
    "# data_list = [\"spambase\", \"climate\"]\n",
    "\n",
    "params = {\n",
    "    \"runs\": 50,\n",
    "    \"n_estimators\": 10,\n",
    "    \"oob\": False,\n",
    "    \"test_split\": 0.3,\n",
    "    \"calib_split\": 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "calib_results_dict = {}\n",
    "\n",
    "for data_name in data_list:\n",
    "\n",
    "    # Data\n",
    "    X, y = dp.load_data(data_name, \"../../\")\n",
    "    \n",
    "    data_dict = {} # results for each data set will be saved in here.\n",
    "    for seed in range(params[\"runs\"]): # running the same dataset multiple times\n",
    "        # split the data\n",
    "        data = cal.split_train_calib_test(data_name, X, y, params[\"test_split\"], params[\"calib_split\"], seed)\n",
    "\n",
    "        # train model\n",
    "        irrf = IR_RF(n_estimators=params[\"n_estimators\"], oob_score=params[\"oob\"], random_state=seed)\n",
    "        irrf.fit(data[\"x_train\"], data[\"y_train\"])\n",
    "\n",
    "        # calibration\n",
    "        res = cal.calibration(irrf, data, calib_methods, metrics) # res is a dict with all the metrics results as well as RF probs and every calibration method decision for every test data point\n",
    "        data_dict = cal.update_runs(data_dict, res) # calib results for every run for the same dataset is aggregated in data_dict (ex. acc of every run as an array)\n",
    "    calib_results_dict.update(data_dict) # merge results of all datasets together\n",
    "    \n",
    "tables = cal.mean_and_ranking_table(calib_results_dict, metrics, calib_methods, data_list, mean_and_rank=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = cal.mean_and_ranking_table(calib_results_dict, metrics, calib_methods, data_list, mean_and_rank=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RF</th>\n",
       "      <th>Platt</th>\n",
       "      <th>ISO</th>\n",
       "      <th>Rank</th>\n",
       "      <th>CRF</th>\n",
       "      <th>VA</th>\n",
       "      <th>Beta</th>\n",
       "      <th>Elkan</th>\n",
       "      <th>tlr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>spambase</th>\n",
       "      <td>0.057521</td>\n",
       "      <td>0.050282</td>\n",
       "      <td>0.050778</td>\n",
       "      <td>0.053053</td>\n",
       "      <td>0.052633</td>\n",
       "      <td>0.050856</td>\n",
       "      <td>0.050744</td>\n",
       "      <td>0.057521</td>\n",
       "      <td>0.057811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>climate</th>\n",
       "      <td>0.065902</td>\n",
       "      <td>0.065348</td>\n",
       "      <td>0.067040</td>\n",
       "      <td>0.089403</td>\n",
       "      <td>0.065331</td>\n",
       "      <td>0.065894</td>\n",
       "      <td>0.065269</td>\n",
       "      <td>0.065902</td>\n",
       "      <td>0.080928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QSAR</th>\n",
       "      <td>0.118648</td>\n",
       "      <td>0.117039</td>\n",
       "      <td>0.119126</td>\n",
       "      <td>0.123763</td>\n",
       "      <td>0.117443</td>\n",
       "      <td>0.119113</td>\n",
       "      <td>0.116980</td>\n",
       "      <td>0.118648</td>\n",
       "      <td>0.126369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bank</th>\n",
       "      <td>0.018635</td>\n",
       "      <td>0.014380</td>\n",
       "      <td>0.014587</td>\n",
       "      <td>0.029375</td>\n",
       "      <td>0.015390</td>\n",
       "      <td>0.015777</td>\n",
       "      <td>0.014548</td>\n",
       "      <td>0.018635</td>\n",
       "      <td>0.016045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>climate</th>\n",
       "      <td>0.065902</td>\n",
       "      <td>0.065348</td>\n",
       "      <td>0.067040</td>\n",
       "      <td>0.089403</td>\n",
       "      <td>0.065331</td>\n",
       "      <td>0.065894</td>\n",
       "      <td>0.065269</td>\n",
       "      <td>0.065902</td>\n",
       "      <td>0.080928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parkinsons</th>\n",
       "      <td>0.115106</td>\n",
       "      <td>0.113709</td>\n",
       "      <td>0.116794</td>\n",
       "      <td>0.162676</td>\n",
       "      <td>0.115121</td>\n",
       "      <td>0.119390</td>\n",
       "      <td>0.113658</td>\n",
       "      <td>0.115106</td>\n",
       "      <td>0.142414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vertebral</th>\n",
       "      <td>0.125767</td>\n",
       "      <td>0.127597</td>\n",
       "      <td>0.133597</td>\n",
       "      <td>0.146293</td>\n",
       "      <td>0.125574</td>\n",
       "      <td>0.134638</td>\n",
       "      <td>0.127561</td>\n",
       "      <td>0.125774</td>\n",
       "      <td>0.132998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ionosphere</th>\n",
       "      <td>0.079163</td>\n",
       "      <td>0.067671</td>\n",
       "      <td>0.069951</td>\n",
       "      <td>0.113383</td>\n",
       "      <td>0.071535</td>\n",
       "      <td>0.072217</td>\n",
       "      <td>0.068081</td>\n",
       "      <td>0.079079</td>\n",
       "      <td>0.074572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>0.176628</td>\n",
       "      <td>0.176860</td>\n",
       "      <td>0.181247</td>\n",
       "      <td>0.177887</td>\n",
       "      <td>0.176833</td>\n",
       "      <td>0.181449</td>\n",
       "      <td>0.176869</td>\n",
       "      <td>0.176622</td>\n",
       "      <td>0.193212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breast</th>\n",
       "      <td>0.041661</td>\n",
       "      <td>0.040443</td>\n",
       "      <td>0.043070</td>\n",
       "      <td>0.063493</td>\n",
       "      <td>0.040895</td>\n",
       "      <td>0.044838</td>\n",
       "      <td>0.040796</td>\n",
       "      <td>0.041661</td>\n",
       "      <td>0.043156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blod</th>\n",
       "      <td>0.175024</td>\n",
       "      <td>0.167757</td>\n",
       "      <td>0.170505</td>\n",
       "      <td>0.171140</td>\n",
       "      <td>0.174994</td>\n",
       "      <td>0.171045</td>\n",
       "      <td>0.167811</td>\n",
       "      <td>0.174944</td>\n",
       "      <td>0.213698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.094542</td>\n",
       "      <td>0.091494</td>\n",
       "      <td>0.093976</td>\n",
       "      <td>0.110897</td>\n",
       "      <td>0.092825</td>\n",
       "      <td>0.094646</td>\n",
       "      <td>0.091599</td>\n",
       "      <td>0.094527</td>\n",
       "      <td>0.105648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <td>5.272727</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>5.363636</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.545455</td>\n",
       "      <td>5.727273</td>\n",
       "      <td>2.090909</td>\n",
       "      <td>5.090909</td>\n",
       "      <td>7.727273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  RF     Platt       ISO      Rank       CRF        VA      Beta     Elkan       tlr\n",
       "Data                                                                                                \n",
       "spambase    0.057521  0.050282  0.050778  0.053053  0.052633  0.050856  0.050744  0.057521  0.057811\n",
       "climate     0.065902  0.065348  0.067040  0.089403  0.065331  0.065894  0.065269  0.065902  0.080928\n",
       "QSAR        0.118648  0.117039  0.119126  0.123763  0.117443  0.119113  0.116980  0.118648  0.126369\n",
       "bank        0.018635  0.014380  0.014587  0.029375  0.015390  0.015777  0.014548  0.018635  0.016045\n",
       "climate     0.065902  0.065348  0.067040  0.089403  0.065331  0.065894  0.065269  0.065902  0.080928\n",
       "parkinsons  0.115106  0.113709  0.116794  0.162676  0.115121  0.119390  0.113658  0.115106  0.142414\n",
       "vertebral   0.125767  0.127597  0.133597  0.146293  0.125574  0.134638  0.127561  0.125774  0.132998\n",
       "ionosphere  0.079163  0.067671  0.069951  0.113383  0.071535  0.072217  0.068081  0.079079  0.074572\n",
       "diabetes    0.176628  0.176860  0.181247  0.177887  0.176833  0.181449  0.176869  0.176622  0.193212\n",
       "breast      0.041661  0.040443  0.043070  0.063493  0.040895  0.044838  0.040796  0.041661  0.043156\n",
       "blod        0.175024  0.167757  0.170505  0.171140  0.174994  0.171045  0.167811  0.174944  0.213698\n",
       "Mean        0.094542  0.091494  0.093976  0.110897  0.092825  0.094646  0.091599  0.094527  0.105648\n",
       "Rank        5.272727  2.181818  5.363636  8.000000  3.545455  5.727273  2.090909  5.090909  7.727273"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[\"brier\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_dict = {} #pd.DataFrame()\n",
    "# for metric in metrics:\n",
    "#     exp_dict[metric] = pd.DataFrame()\n",
    "\n",
    "# for exp_sample_size in params[\"calib_size\"]:\n",
    "\n",
    "#     calib_results_dict = {}\n",
    "#     for data_name in data_list:\n",
    "#         # Data\n",
    "#         X, y = dp.load_data(data_name, \"../../\")\n",
    "#         # X, y, tp = dp.make_classification_gaussian_with_true_prob(30, 4, 0)\n",
    "#         # split to train calib test\n",
    "\n",
    "#         data_dict = {}\n",
    "#         for seed in range(params[\"runs\"]):\n",
    "#             # split the data\n",
    "#             data = cal.split_train_calib_test(data_name, X, y, params[\"test_split\"], params[\"calib_split\"], seed)\n",
    "#             # reset the calibration set size based on exp_sample_size percentage (for this experiment)\n",
    "#             calib_size = int(exp_sample_size / 100 * len(data[\"x_calib\"]))\n",
    "#             for start_index in range(len(data[\"x_calib\"]) - calib_size): # the for is to find a subset of calib data such that it contains all the class lables\n",
    "#                 if len(np.unique(data[\"y_calib\"][start_index : start_index+calib_size])) > 1: \n",
    "#                     data[\"x_calib\"] = data[\"x_calib\"][start_index : start_index+calib_size]\n",
    "#                     data[\"y_calib\"] = data[\"y_calib\"][start_index : start_index+calib_size]\n",
    "#                     break\n",
    "#             # train model\n",
    "#             irrf = IR_RF(n_estimators=params[\"n_estimators\"], oob_score=params[\"oob\"], random_state=seed)\n",
    "#             irrf.fit(data[\"x_train\"], data[\"y_train\"])\n",
    "#             # calibration\n",
    "#             res = cal.calibration(irrf, data, calib_methods, metrics)\n",
    "#             # print(\"run res\\n\", res)\n",
    "#             data_dict = cal.update_runs(data_dict, res)\n",
    "\n",
    "#         calib_results_dict.update(data_dict) # merge results of all datasets together\n",
    "\n",
    "#     tables = cal.mean_and_ranking_table(calib_results_dict, metrics, calib_methods, data_list)\n",
    "#     # print(\"tables\", tables)\n",
    "#     # exit()\n",
    "#     exp_dict = cal.exp_mean_rank_through_time(exp_dict, tables, exp_sample_size, \"rank\", \"Calibration sample size\")\n",
    "\n",
    "#     # calib_ranks = table.iloc[-1].to_dict()\n",
    "#     # calib_ranks[\"Calibration sample size\"] = exp_sample_size\n",
    "#     # exp_dict = pd.concat([exp_dict, (pd.DataFrame([calib_ranks]))])\n",
    "#     # print(f\"exp_sample_size {exp_sample_size} done\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
